from flask import Flask, request
import requests
import numpy as np
import pandas as pd
import pickle
import random
import deepcut
import tensorflow as tf
load_model = tf.keras.models.load_model
pad_sequences = tf.keras.preprocessing.sequence.pad_sequences
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from pythainlp.tokenize import word_tokenize


#  ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
model = load_model("C:/Users/User/Desktop/‡∏á‡∏≤‡∏ô ‡∏õ‡∏µ 3 ‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏ö/Data Chatbot/Modeling/trained_model.keras")

#  ‡πÇ‡∏´‡∏•‡∏î Tokenizer
with open("Modeling/tokenizer.pkl", "rb") as handle:
    tokenizer = pickle.load(handle)

#  ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel
file_path = "Modeling/QuestionAnswer_AI.xlsx"
sheets = pd.read_excel(file_path, sheet_name=None)
df_answers = sheets["Answer"]
df_question = sheets["QuestionAnswer"]
merged_df = df_question.merge(df_answers, on="answer", how="left")

# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô dictionary ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ sub_questions ‡πÄ‡∏õ‡πá‡∏ô key ‡πÅ‡∏•‡∏∞ detail ‡πÄ‡∏õ‡πá‡∏ô value
question_answer_dict = dict(zip(merged_df["sub_questions"], merged_df["detail"]))

#  ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Facebook API
PAGE_ACCESS_TOKEN = "EAAZAnUGahizwBO1blzD18zkZCtFZAdLIOqJlvqJ8e45YgggZAUrX7SICFtykZAc3iZCi85HZC4otsV7QWpz4ZCBnN9ZCbU8Im1OKroZB9UHVIDISVMCUTofGzemqTuo8BMRMzuNspUSOLea0Fs1i6CUwmZAvjwegwG3YV4gWxH08VmRxPI5t3uL9EeTlnYVoEHJTlPIaQZDZD"
VERIFY_TOKEN = "b_heeeeem"

#  ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥
processed_messages = set()

app = Flask(__name__)

#  ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ deepcut
def custom_tokenize(text):
    return deepcut.tokenize(text)

#  ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏ä‡πâ `cosine similarity` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
#def find_best_answer(question, possible_answers):
    vectorizer = TfidfVectorizer(ngram_range=(1,2), tokenizer=custom_tokenize)
    vectors = vectorizer.fit_transform([question] + possible_answers)
    cosine_sim = cosine_similarity(vectors[0], vectors[1:])
    best_match_index = cosine_sim.argmax()
    return possible_answers[best_match_index]

#  ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
def preprocess_question(text):
    # ‡∏•‡∏ö "‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ" ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Bias
    #text = text.replace("‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ", "").strip()
    return text

def predict_answer(text, threshold=0.4):
    original_text = text  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏ß‡πâ
    text = preprocess_question(text)  # ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    
    if text in question_answer_dict:
        return "direct_match", None, question_answer_dict[text]

    tokens = custom_tokenize(text)
    print(f"üìå DEBUG: ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å deepcut = {tokens}")

    seq = tokenizer.texts_to_sequences([tokens])
    padded = pad_sequences(seq, maxlen=10, padding="post")
    pred = model.predict(padded)

    confidence_scores = pred[0]
    predicted_class = np.argmax(confidence_scores)
    max_confidence = np.max(confidence_scores)

    print(f"üìå DEBUG: ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå class = {predicted_class}, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à = {max_confidence}")
    print(f"üìå DEBUG: ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î = {confidence_scores}")

    if max_confidence < threshold:
        return "unknown", confidence_scores, f"‡∏Ç‡∏≠‡πÇ‡∏ó‡∏© ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° '{original_text}'"

    response_options = df_answers[df_answers["answer"] == predicted_class]["detail"].tolist()

    best_response = random.choice(response_options) if response_options else "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏© ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ"
    
    return predicted_class, confidence_scores, best_response

#  ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Webhook ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å Messenger
@app.route("/webhook", methods=["GET", "POST"])
def webhook():
    if request.method == "GET":
        mode = request.args.get("hub.mode")
        token = request.args.get("hub.verify_token")
        challenge = request.args.get("hub.challenge")

        if mode == "subscribe" and token == VERIFY_TOKEN:
            print(" Webhook Verified!")
            return challenge, 200
        return "Verification token mismatch", 403

    elif request.method == "POST":
        data = request.json
        print("üìå DEBUG: Received Data:", data)

        for entry in data.get("entry", []):
            for messaging_event in entry.get("messaging", []):
                if "message" in messaging_event and "is_echo" not in messaging_event["message"]:
                    sender_id = messaging_event["sender"]["id"]
                    message_text = messaging_event["message"].get("text", "(‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)")
                    message_id = messaging_event["message"]["mid"]

                    #  ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥
                    if message_id in processed_messages:
                        print(f"‚ö†Ô∏è Duplicate message detected: {message_text}")
                        continue
                    processed_messages.add(message_id)

                    print(f"üì© Received message from {sender_id}: {message_text}")

                    #  ‡πÉ‡∏ä‡πâ AI chatbot ‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
                    _, _, response = predict_answer(message_text)

                    #  ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
                    send_message(sender_id, response)

        return "OK", 200

#  ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà Messenger
def send_message(recipient_id, text):
    url = f"https://graph.facebook.com/v17.0/me/messages?access_token={PAGE_ACCESS_TOKEN}"
    data = {"recipient": {"id": recipient_id}, "message": {"text": text}}
    headers = {"Content-Type": "application/json"}

    response = requests.post(url, json=data, headers=headers)
    print("üìå Response from Facebook:", response.json())

if __name__ == "__main__":
    app.run(port=5000, debug=True)
